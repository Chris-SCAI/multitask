// AI Features - Smart task management

import { callLLM, isLLMConfigured, LLMMessage } from './llm-providers'
import { Task } from './types'

export interface EisenhowerResult {
  quadrant: 'urgent-important' | 'not-urgent-important' | 'urgent-not-important' | 'not-urgent-not-important'
  reasoning: string
  suggestedPriority: 'high' | 'medium' | 'low'
  suggestedStars: 1 | 2 | 3
}

export interface TaskSuggestion {
  subtasks?: string[]
  improvedTitle?: string
  estimatedMinutes?: number
  tags?: string[]
}

// Eisenhower Matrix Classification
export async function classifyEisenhower(task: Task): Promise<EisenhowerResult> {
  if (!isLLMConfigured()) {
    throw new Error('IA non configur√©e. Ajoutez votre cl√© API dans les param√®tres.')
  }

  const prompt = `Tu es un expert en productivit√© et gestion du temps. Analyse cette t√¢che selon la matrice d'Eisenhower.

T√ÇCHE:
- Titre: ${task.title}
${task.description ? `- Description: ${task.description}` : ''}
${task.deadline ? `- √âch√©ance: ${new Date(task.deadline).toLocaleDateString('fr-FR')}` : '- Pas d\'√©ch√©ance'}
- Priorit√© actuelle: ${task.priority}

R√©ponds en JSON avec ce format exact:
{
  "quadrant": "urgent-important" | "not-urgent-important" | "urgent-not-important" | "not-urgent-not-important",
  "reasoning": "explication courte en fran√ßais",
  "suggestedPriority": "high" | "medium" | "low",
  "suggestedStars": 1 | 2 | 3
}

Crit√®res:
- URGENT = √©ch√©ance proche (<3 jours) ou cons√©quences imm√©diates si non fait
- IMPORTANT = impact significatif sur objectifs long terme, carri√®re, sant√©, relations

Quadrants:
- urgent-important (Q1): Faire imm√©diatement ‚Üí high, 3 √©toiles
- not-urgent-important (Q2): Planifier ‚Üí medium, 2 √©toiles  
- urgent-not-important (Q3): D√©l√©guer si possible ‚Üí medium, 1 √©toile
- not-urgent-not-important (Q4): √âliminer ou reporter ‚Üí low, 0 √©toiles

R√©ponds UNIQUEMENT avec le JSON, sans texte avant ou apr√®s.`

  const response = await callLLM([
    { role: 'user', content: prompt }
  ])

  try {
    // Extract JSON from response
    const jsonMatch = response.content.match(/\{[\s\S]*\}/)
    if (!jsonMatch) {
      throw new Error('Invalid response format')
    }
    return JSON.parse(jsonMatch[0])
  } catch (error) {
    console.error('Error parsing Eisenhower response:', error)
    throw new Error('Erreur lors de l\'analyse de la t√¢che')
  }
}

// Get task suggestions (subtasks, improved title, etc.)
export async function getTaskSuggestions(task: Task): Promise<TaskSuggestion> {
  if (!isLLMConfigured()) {
    throw new Error('IA non configur√©e. Ajoutez votre cl√© API dans les param√®tres.')
  }

  const prompt = `Tu es un assistant de productivit√©. Analyse cette t√¢che et sugg√®re des am√©liorations.

T√ÇCHE:
- Titre: ${task.title}
${task.description ? `- Description: ${task.description}` : ''}

R√©ponds en JSON avec ce format:
{
  "subtasks": ["sous-t√¢che 1", "sous-t√¢che 2", ...] (3-5 √©tapes concr√®tes pour accomplir la t√¢che),
  "improvedTitle": "titre am√©lior√© si le titre actuel est vague" (ou null si le titre est d√©j√† clair),
  "estimatedMinutes": nombre (estimation du temps total en minutes),
  "tags": ["tag1", "tag2"] (2-3 tags pertinents pour cat√©goriser)
}

R√©ponds UNIQUEMENT avec le JSON, sans texte avant ou apr√®s.`

  const response = await callLLM([
    { role: 'user', content: prompt }
  ])

  try {
    const jsonMatch = response.content.match(/\{[\s\S]*\}/)
    if (!jsonMatch) {
      throw new Error('Invalid response format')
    }
    return JSON.parse(jsonMatch[0])
  } catch (error) {
    console.error('Error parsing suggestions response:', error)
    throw new Error('Erreur lors de la g√©n√©ration des suggestions')
  }
}

// Analyze multiple tasks and suggest focus
export async function suggestFocus(tasks: Task[]): Promise<string> {
  if (!isLLMConfigured()) {
    throw new Error('IA non configur√©e. Ajoutez votre cl√© API dans les param√®tres.')
  }

  const incompleteTasks = tasks.filter(t => !t.completed).slice(0, 10) // Limit to 10 tasks
  
  if (incompleteTasks.length === 0) {
    return "Bravo ! Tu as termin√© toutes tes t√¢ches. üéâ"
  }

  const taskList = incompleteTasks.map((t, i) => {
    let info = `${i + 1}. "${t.title}"`
    if (t.deadline) info += ` (√©ch√©ance: ${new Date(t.deadline).toLocaleDateString('fr-FR')})`
    if (t.priority === 'high') info += ' [URGENT]'
    if (t.stars && t.stars >= 2) info += ` [${'‚≠ê'.repeat(t.stars)}]`
    return info
  }).join('\n')

  const prompt = `Tu es un coach de productivit√© bienveillant. Voici les t√¢ches en cours:

${taskList}

En 2-3 phrases max, donne un conseil personnalis√© et motivant sur quelle t√¢che attaquer en premier et pourquoi. Sois direct et concret. Utilise le tutoiement.`

  const response = await callLLM([
    { role: 'user', content: prompt }
  ])

  return response.content.trim()
}

// Batch classify multiple tasks
export async function batchClassifyEisenhower(tasks: Task[]): Promise<Map<string, EisenhowerResult>> {
  const results = new Map<string, EisenhowerResult>()
  
  // Process in parallel with limit
  const batchSize = 3
  for (let i = 0; i < tasks.length; i += batchSize) {
    const batch = tasks.slice(i, i + batchSize)
    const promises = batch.map(async (task) => {
      try {
        const result = await classifyEisenhower(task)
        results.set(task.id, result)
      } catch (error) {
        console.error(`Error classifying task ${task.id}:`, error)
      }
    })
    await Promise.all(promises)
  }
  
  return results
}

// ============================================
// TASK ANALYSIS & OPTIMIZATION
// ============================================

export type AnalysisPeriod = 'today' | 'week' | 'month' | 'all'

export interface TimeBlock {
  taskId: string
  taskTitle: string
  suggestedStart: string // "09:00"
  suggestedEnd: string   // "10:30"
  reason: string
}

export interface TaskGroup {
  name: string
  taskIds: string[]
  reason: string
  suggestedOrder: string[]
}

export interface Conflict {
  type: 'overload' | 'deadline_clash' | 'unrealistic' | 'dependency'
  severity: 'low' | 'medium' | 'high'
  description: string
  affectedTaskIds: string[]
  suggestion: string
}

export interface PriorityChange {
  taskId: string
  taskTitle: string
  currentPriority: string
  suggestedPriority: string
  currentStars: number | undefined
  suggestedStars: number
  reason: string
}

export interface OptimizationSuggestion {
  type: 'delegate' | 'batch' | 'eliminate' | 'reschedule' | 'split' | 'automate'
  description: string
  affectedTaskIds: string[]
  impact: 'low' | 'medium' | 'high'
}

export interface AnalysisResult {
  period: AnalysisPeriod
  analyzedAt: Date
  summary: {
    totalTasks: number
    completedTasks: number
    overdueTasks: number
    highPriorityTasks: number
    estimatedHours: number
    workloadAssessment: 'light' | 'balanced' | 'heavy' | 'overloaded'
  }
  timeBlocking: TimeBlock[]
  taskGroups: TaskGroup[]
  conflicts: Conflict[]
  priorityChanges: PriorityChange[]
  optimizations: OptimizationSuggestion[]
  aiInsights: string
}

export interface Workspace {
  id: string
  name: string
}

// Main analysis function
export async function analyzeAndOptimizeTasks(
  tasks: Task[],
  workspaces: Workspace[],
  period: AnalysisPeriod = 'week'
): Promise<AnalysisResult> {
  if (!isLLMConfigured()) {
    throw new Error('IA non configur√©e. Ajoutez votre cl√© API dans les param√®tres.')
  }

  const now = new Date()
  const filteredTasks = filterTasksByPeriod(tasks, period)
  const incompleteTasks = filteredTasks.filter(t => !t.completed && !t.parentId)

  if (incompleteTasks.length === 0) {
    return {
      period,
      analyzedAt: now,
      summary: {
        totalTasks: 0,
        completedTasks: filteredTasks.filter(t => t.completed).length,
        overdueTasks: 0,
        highPriorityTasks: 0,
        estimatedHours: 0,
        workloadAssessment: 'light',
      },
      timeBlocking: [],
      taskGroups: [],
      conflicts: [],
      priorityChanges: [],
      optimizations: [],
      aiInsights: "Aucune t√¢che √† analyser pour cette p√©riode. Bravo, tu es √† jour ! üéâ",
    }
  }

  // Build task context for AI
  const workspaceMap = new Map(workspaces.map(w => [w.id, w.name]))
  const taskContext = incompleteTasks.map((t, i) => {
    const ws = workspaceMap.get(t.workspaceId) || 'Inconnu'
    const deadline = t.deadline ? new Date(t.deadline).toLocaleDateString('fr-FR') : 'Pas de deadline'
    const stars = t.stars ? '‚≠ê'.repeat(t.stars) : ''
    return `${i + 1}. [${ws}] "${t.title}" | Type: ${t.taskType} | Priorit√©: ${t.priority} ${stars} | Deadline: ${deadline}`
  }).join('\n')

  const prompt = `Tu es un expert en productivit√© et gestion du temps. Analyse ces t√¢ches et propose des optimisations concr√®tes.

DATE ACTUELLE: ${now.toLocaleDateString('fr-FR')} (${now.toLocaleDateString('fr-FR', { weekday: 'long' })})
P√âRIODE D'ANALYSE: ${getPeriodLabel(period)}

T√ÇCHES √Ä ANALYSER (${incompleteTasks.length}):
${taskContext}

R√©ponds en JSON avec ce format exact:
{
  "summary": {
    "estimatedHours": <nombre total d'heures estim√©es>,
    "workloadAssessment": "light" | "balanced" | "heavy" | "overloaded"
  },
  "timeBlocking": [
    {
      "taskIndex": <num√©ro de la t√¢che>,
      "suggestedStart": "HH:MM",
      "suggestedEnd": "HH:MM", 
      "reason": "pourquoi ce cr√©neau"
    }
  ],
  "taskGroups": [
    {
      "name": "nom du groupe",
      "taskIndices": [<indices des t√¢ches>],
      "reason": "pourquoi regrouper",
      "suggestedOrder": [<indices dans l'ordre optimal>]
    }
  ],
  "conflicts": [
    {
      "type": "overload" | "deadline_clash" | "unrealistic" | "dependency",
      "severity": "low" | "medium" | "high",
      "description": "description du conflit",
      "taskIndices": [<indices concern√©s>],
      "suggestion": "comment r√©soudre"
    }
  ],
  "priorityChanges": [
    {
      "taskIndex": <num√©ro>,
      "currentPriority": "low|medium|high",
      "suggestedPriority": "low|medium|high",
      "suggestedStars": 0|1|2|3,
      "reason": "pourquoi ce changement"
    }
  ],
  "optimizations": [
    {
      "type": "delegate" | "batch" | "eliminate" | "reschedule" | "split" | "automate",
      "description": "action concr√®te √† prendre",
      "taskIndices": [<indices concern√©s>],
      "impact": "low" | "medium" | "high"
    }
  ],
  "aiInsights": "2-3 phrases de conseil personnalis√© et motivant"
}

R√àGLES:
- timeBlocking: propose un planning r√©aliste (8h-19h, pauses incluses)
- taskGroups: regroupe par contexte similaire (m√™me workspace, m√™me type, m√™me √©nergie requise)
- conflicts: d√©tecte surcharge, deadlines irr√©alistes, t√¢ches qui s'entrechoquent
- priorityChanges: sugg√®re uniquement si vraiment justifi√©
- optimizations: propose des actions concr√®tes (d√©l√©guer, automatiser, d√©couper, reporter)
- aiInsights: sois direct, concret et bienveillant

R√©ponds UNIQUEMENT avec le JSON, sans texte avant ou apr√®s.`

  const response = await callLLM([{ role: 'user', content: prompt }])

  try {
    const jsonMatch = response.content.match(/\{[\s\S]*\}/)
    if (!jsonMatch) {
      throw new Error('Invalid response format')
    }
    const aiResult = JSON.parse(jsonMatch[0])

    // Map indices back to task IDs
    const indexToTask = (idx: number) => incompleteTasks[idx - 1]

    return {
      period,
      analyzedAt: now,
      summary: {
        totalTasks: incompleteTasks.length,
        completedTasks: filteredTasks.filter(t => t.completed).length,
        overdueTasks: incompleteTasks.filter(t => t.deadline && new Date(t.deadline) < now).length,
        highPriorityTasks: incompleteTasks.filter(t => t.priority === 'high').length,
        estimatedHours: aiResult.summary?.estimatedHours || 0,
        workloadAssessment: aiResult.summary?.workloadAssessment || 'balanced',
      },
      timeBlocking: (aiResult.timeBlocking || []).map((tb: any) => {
        const task = indexToTask(tb.taskIndex)
        return task ? {
          taskId: task.id,
          taskTitle: task.title,
          suggestedStart: tb.suggestedStart,
          suggestedEnd: tb.suggestedEnd,
          reason: tb.reason,
        } : null
      }).filter(Boolean),
      taskGroups: (aiResult.taskGroups || []).map((g: any) => ({
        name: g.name,
        taskIds: (g.taskIndices || []).map((i: number) => indexToTask(i)?.id).filter(Boolean),
        reason: g.reason,
        suggestedOrder: (g.suggestedOrder || []).map((i: number) => indexToTask(i)?.id).filter(Boolean),
      })),
      conflicts: (aiResult.conflicts || []).map((c: any) => ({
        type: c.type,
        severity: c.severity,
        description: c.description,
        affectedTaskIds: (c.taskIndices || []).map((i: number) => indexToTask(i)?.id).filter(Boolean),
        suggestion: c.suggestion,
      })),
      priorityChanges: (aiResult.priorityChanges || []).map((pc: any) => {
        const task = indexToTask(pc.taskIndex)
        return task ? {
          taskId: task.id,
          taskTitle: task.title,
          currentPriority: pc.currentPriority,
          suggestedPriority: pc.suggestedPriority,
          currentStars: task.stars,
          suggestedStars: pc.suggestedStars,
          reason: pc.reason,
        } : null
      }).filter(Boolean),
      optimizations: (aiResult.optimizations || []).map((o: any) => ({
        type: o.type,
        description: o.description,
        affectedTaskIds: (o.taskIndices || []).map((i: number) => indexToTask(i)?.id).filter(Boolean),
        impact: o.impact,
      })),
      aiInsights: aiResult.aiInsights || "Analyse termin√©e.",
    }
  } catch (error) {
    console.error('Error parsing analysis response:', error)
    throw new Error('Erreur lors de l\'analyse des t√¢ches')
  }
}

function filterTasksByPeriod(tasks: Task[], period: AnalysisPeriod): Task[] {
  const now = new Date()
  const startOfToday = new Date(now.getFullYear(), now.getMonth(), now.getDate())

  switch (period) {
    case 'today':
      return tasks.filter(t => {
        if (!t.deadline) return false
        const deadline = new Date(t.deadline)
        return deadline >= startOfToday && deadline < new Date(startOfToday.getTime() + 24 * 60 * 60 * 1000)
      })
    case 'week':
      const endOfWeek = new Date(startOfToday.getTime() + 7 * 24 * 60 * 60 * 1000)
      return tasks.filter(t => {
        if (!t.deadline) return true // Include tasks without deadline
        const deadline = new Date(t.deadline)
        return deadline < endOfWeek
      })
    case 'month':
      const endOfMonth = new Date(startOfToday.getTime() + 30 * 24 * 60 * 60 * 1000)
      return tasks.filter(t => {
        if (!t.deadline) return true
        const deadline = new Date(t.deadline)
        return deadline < endOfMonth
      })
    case 'all':
    default:
      return tasks
  }
}

function getPeriodLabel(period: AnalysisPeriod): string {
  switch (period) {
    case 'today': return "Aujourd'hui"
    case 'week': return 'Les 7 prochains jours'
    case 'month': return 'Les 30 prochains jours'
    case 'all': return 'Toutes les t√¢ches'
  }
}

// ============================================
// WEEKLY REPORT
// ============================================

export interface WeeklyStats {
  tasksCompleted: number
  tasksCreated: number
  tasksOverdue: number
  completionRate: number
  mostProductiveDay: string
  topWorkspace: string
  averageCompletionTime: number // en jours
}

export interface WeeklyReportResult {
  period: { start: Date; end: Date }
  stats: WeeklyStats
  accomplishments: string[]
  areasToImprove: string[]
  weeklyScore: number // 0-100
  motivation: string
  nextWeekTip: string
}

export async function generateWeeklyReport(
  tasks: Task[],
  workspaces: Workspace[]
): Promise<WeeklyReportResult> {
  if (!isLLMConfigured()) {
    throw new Error('IA non configur√©e. Ajoutez votre cl√© API dans les param√®tres.')
  }

  const now = new Date()
  const weekAgo = new Date(now.getTime() - 7 * 24 * 60 * 60 * 1000)
  
  const workspaceMap = new Map(workspaces.map(w => [w.id, w.name]))

  // T√¢ches compl√©t√©es cette semaine
  const completedThisWeek = tasks.filter(t => {
    if (!t.completed || !t.completedAt) return false
    const completedDate = new Date(t.completedAt)
    return completedDate >= weekAgo && completedDate <= now
  })

  // T√¢ches cr√©√©es cette semaine
  const createdThisWeek = tasks.filter(t => {
    const createdDate = new Date(t.createdAt)
    return createdDate >= weekAgo && createdDate <= now
  })

  // T√¢ches en retard
  const overdueTasks = tasks.filter(t => {
    if (t.completed || !t.deadline) return false
    return new Date(t.deadline) < now
  })

  // Stats par workspace
  const workspaceStats = new Map<string, number>()
  completedThisWeek.forEach(t => {
    const wsName = workspaceMap.get(t.workspaceId) || 'Inconnu'
    workspaceStats.set(wsName, (workspaceStats.get(wsName) || 0) + 1)
  })
  const topWorkspace = Array.from(workspaceStats.entries()).sort((a, b) => b[1] - a[1])[0]?.[0] || 'Aucun'

  // Stats par jour
  const dayStats = new Map<string, number>()
  const dayNames = ['Dimanche', 'Lundi', 'Mardi', 'Mercredi', 'Jeudi', 'Vendredi', 'Samedi']
  completedThisWeek.forEach(t => {
    if (!t.completedAt) return
    const dayName = dayNames[new Date(t.completedAt).getDay()]
    dayStats.set(dayName, (dayStats.get(dayName) || 0) + 1)
  })
  const mostProductiveDay = Array.from(dayStats.entries()).sort((a, b) => b[1] - a[1])[0]?.[0] || 'Aucun'

  // Calcul du taux de compl√©tion
  const completionRate = createdThisWeek.length > 0 
    ? Math.round((completedThisWeek.length / createdThisWeek.length) * 100)
    : 0

  const stats: WeeklyStats = {
    tasksCompleted: completedThisWeek.length,
    tasksCreated: createdThisWeek.length,
    tasksOverdue: overdueTasks.length,
    completionRate,
    mostProductiveDay,
    topWorkspace,
    averageCompletionTime: 0,
  }

  // Contexte pour l'IA
  const completedList = completedThisWeek.slice(0, 10).map(t => {
    const ws = workspaceMap.get(t.workspaceId) || 'Inconnu'
    return `- [${ws}] ${t.title}`
  }).join('\n')

  const overdueList = overdueTasks.slice(0, 5).map(t => {
    const ws = workspaceMap.get(t.workspaceId) || 'Inconnu'
    return `- [${ws}] ${t.title}`
  }).join('\n')

  const prompt = `Tu es un coach productivit√©. G√©n√®re un rapport hebdomadaire motivant.

STATISTIQUES DE LA SEMAINE:
- T√¢ches compl√©t√©es: ${stats.tasksCompleted}
- T√¢ches cr√©√©es: ${stats.tasksCreated}
- Taux de compl√©tion: ${stats.completionRate}%
- En retard: ${stats.tasksOverdue}
- Jour le plus productif: ${stats.mostProductiveDay}
- Workspace favori: ${stats.topWorkspace}

T√ÇCHES COMPL√âT√âES (top 10):
${completedList || 'Aucune'}

T√ÇCHES EN RETARD:
${overdueList || 'Aucune'}

R√©ponds en JSON avec ce format:
{
  "weeklyScore": <score de 0 √† 100 bas√© sur la performance>,
  "accomplishments": ["accomplissement 1", "accomplissement 2", "accomplissement 3"],
  "areasToImprove": ["point d'am√©lioration 1", "point d'am√©lioration 2"],
  "motivation": "message motivant personnalis√© (2 phrases)",
  "nextWeekTip": "conseil actionnable pour la semaine prochaine"
}

R√àGLES:
- weeklyScore: 80+ excellent, 60-80 bien, 40-60 moyen, <40 √† am√©liorer
- accomplishments: 2-3 points positifs concrets
- areasToImprove: 1-2 points constructifs (pas de jugement)
- Sois encourageant et concret

R√©ponds UNIQUEMENT avec le JSON.`

  const response = await callLLM([{ role: 'user', content: prompt }])

  try {
    const jsonMatch = response.content.match(/\{[\s\S]*\}/)
    if (!jsonMatch) {
      throw new Error('Invalid response format')
    }
    const aiResult = JSON.parse(jsonMatch[0])

    return {
      period: { start: weekAgo, end: now },
      stats,
      accomplishments: aiResult.accomplishments || [],
      areasToImprove: aiResult.areasToImprove || [],
      weeklyScore: aiResult.weeklyScore || 50,
      motivation: aiResult.motivation || 'Continue comme √ßa !',
      nextWeekTip: aiResult.nextWeekTip || 'Planifie ta semaine le dimanche soir.',
    }
  } catch (error) {
    console.error('Error parsing weekly report response:', error)
    throw new Error('Erreur lors de la g√©n√©ration du rapport')
  }
}

// ============================================
// TASK ASSISTANT - Conversational AI
// ============================================

export interface AssistantMessage {
  role: 'user' | 'assistant'
  content: string
  timestamp: Date
}

export async function askTaskAssistant(
  question: string,
  tasks: Task[],
  workspaces: Workspace[],
  conversationHistory: AssistantMessage[] = []
): Promise<string> {
  if (!isLLMConfigured()) {
    throw new Error('IA non configur√©e. Ajoutez votre cl√© API dans les param√®tres.')
  }

  const now = new Date()
  const workspaceMap = new Map(workspaces.map(w => [w.id, w.name]))
  
  const incompleteTasks = tasks.filter(t => !t.completed && !t.parentId)
  const completedToday = tasks.filter(t => {
    if (!t.completed || !t.completedAt) return false
    const completedDate = new Date(t.completedAt)
    return completedDate.toDateString() === now.toDateString()
  })

  const overdueTasks = incompleteTasks.filter(t => t.deadline && new Date(t.deadline) < now)
  const todayTasks = incompleteTasks.filter(t => {
    if (!t.deadline) return false
    return new Date(t.deadline).toDateString() === now.toDateString()
  })

  const taskSummary = incompleteTasks.slice(0, 10).map((t, i) => {
    const ws = workspaceMap.get(t.workspaceId) || 'Inconnu'
    const deadline = t.deadline ? new Date(t.deadline).toLocaleDateString('fr-FR') : 'Sans deadline'
    const stars = t.stars ? '‚≠ê'.repeat(t.stars) : ''
    return `${i + 1}. [${ws}] "${t.title}" - ${t.priority} ${stars} - ${deadline}`
  }).join('\n')

  const contextPrompt = `Tu es un assistant productivit√© bienveillant et efficace. Tu aides l'utilisateur √† g√©rer ses t√¢ches.

CONTEXTE ACTUEL (${now.toLocaleDateString('fr-FR')} ${now.toLocaleTimeString('fr-FR', { hour: '2-digit', minute: '2-digit' })}):
- T√¢ches en cours: ${incompleteTasks.length}
- En retard: ${overdueTasks.length}
- √Ä faire aujourd'hui: ${todayTasks.length}
- Termin√©es aujourd'hui: ${completedToday.length}
- Workspaces: ${workspaces.map(w => w.name).join(', ')}

TOP 10 T√ÇCHES EN COURS:
${taskSummary || 'Aucune t√¢che'}

R√àGLES:
- R√©ponds de fa√ßon concise (2-4 phrases max)
- Sois direct et actionnable
- Utilise le tutoiement
- Si on te demande de cr√©er/modifier des t√¢ches, explique comment le faire dans l'app
- Tu peux donner des conseils de productivit√©
- Si la question n'est pas li√©e aux t√¢ches, r√©ponds poliment que tu es sp√©cialis√© dans la gestion de t√¢ches`

  const messages: LLMMessage[] = [
    { role: 'system', content: contextPrompt },
  ]

  // Add conversation history (last 6 messages max)
  const recentHistory = conversationHistory.slice(-6)
  for (const msg of recentHistory) {
    messages.push({
      role: msg.role === 'user' ? 'user' : 'assistant',
      content: msg.content,
    })
  }

  messages.push({ role: 'user', content: question })

  const response = await callLLM(messages)
  return response.content.trim()
}

// ============================================
// DURATION PREDICTION
// ============================================

export interface DurationPrediction {
  estimatedMinutes: number
  confidence: 'low' | 'medium' | 'high'
  breakdown: string
  tips: string[]
}

export async function predictDuration(task: Task, subtasks: string[] = []): Promise<DurationPrediction> {
  if (!isLLMConfigured()) {
    throw new Error('IA non configur√©e. Ajoutez votre cl√© API dans les param√®tres.')
  }

  const subtaskContext = subtasks.length > 0
    ? `\nSOUS-T√ÇCHES:\n${subtasks.map((s, i) => `${i + 1}. ${s}`).join('\n')}`
    : ''

  const prompt = `Tu es un expert en estimation de temps et productivit√©. Estime la dur√©e de cette t√¢che.

T√ÇCHE:
- Titre: ${task.title}
${task.description ? `- Description: ${task.description}` : ''}
- Type: ${task.taskType}
- Priorit√©: ${task.priority}
${subtaskContext}

R√©ponds en JSON avec ce format exact:
{
  "estimatedMinutes": <dur√©e totale en minutes>,
  "confidence": "low" | "medium" | "high",
  "breakdown": "explication courte de l'estimation",
  "tips": ["conseil 1 pour gagner du temps", "conseil 2"]
}

R√àGLES D'ESTIMATION:
- reunion/rdv: inclure pr√©paration (15min) + dur√©e estim√©e + compte-rendu si n√©cessaire
- livrable: selon complexit√© (simple 30-60min, moyen 1-3h, complexe 3h+)
- admin: g√©n√©ralement 15-45min
- Ajoute 20% de marge pour les impr√©vus
- confidence: high si t√¢che bien d√©finie, low si vague
- 2 tips max pour optimiser le temps

R√©ponds UNIQUEMENT avec le JSON, sans texte avant ou apr√®s.`

  const response = await callLLM([{ role: 'user', content: prompt }])

  try {
    const jsonMatch = response.content.match(/\{[\s\S]*\}/)
    if (!jsonMatch) {
      throw new Error('Invalid response format')
    }
    const aiResult = JSON.parse(jsonMatch[0])

    return {
      estimatedMinutes: aiResult.estimatedMinutes || 30,
      confidence: aiResult.confidence || 'medium',
      breakdown: aiResult.breakdown || '',
      tips: aiResult.tips || [],
    }
  } catch (error) {
    console.error('Error parsing duration prediction response:', error)
    throw new Error('Erreur lors de l\'estimation')
  }
}

// ============================================
// SUBTASK GENERATION
// ============================================

export interface GeneratedSubtask {
  title: string
  estimatedMinutes: number
  order: number
}

export interface SubtaskGenerationResult {
  subtasks: GeneratedSubtask[]
  totalEstimatedMinutes: number
  tip: string
}

export async function generateSubtasks(
  task: Task,
  existingSubtasks: string[] = []
): Promise<SubtaskGenerationResult> {
  if (!isLLMConfigured()) {
    throw new Error('IA non configur√©e. Ajoutez votre cl√© API dans les param√®tres.')
  }

  const existingContext = existingSubtasks.length > 0
    ? `\nSOUS-T√ÇCHES EXISTANTES:\n${existingSubtasks.map((s, i) => `- ${s}`).join('\n')}`
    : ''

  const prompt = `Tu es un expert en gestion de projet. D√©compose cette t√¢che en sous-t√¢ches concr√®tes et actionnables.

T√ÇCHE:
- Titre: ${task.title}
${task.description ? `- Description: ${task.description}` : ''}
- Type: ${task.taskType}
${task.deadline ? `- Deadline: ${new Date(task.deadline).toLocaleDateString('fr-FR')}` : ''}
${existingContext}

R√©ponds en JSON avec ce format exact:
{
  "subtasks": [
    {
      "title": "titre court et actionnable (verbe √† l'infinitif)",
      "estimatedMinutes": <dur√©e en minutes>
    }
  ],
  "tip": "conseil pour bien ex√©cuter cette t√¢che (1 phrase)"
}

R√àGLES:
- G√©n√®re 3 √† 6 sous-t√¢ches selon la complexit√©
- Chaque sous-t√¢che doit √™tre concr√®te et r√©alisable en une session
- Commence par un verbe d'action (R√©diger, Envoyer, Pr√©parer, V√©rifier, etc.)
- Ordonne logiquement (ce qui doit √™tre fait en premier en haut)
- Si des sous-t√¢ches existent d√©j√†, compl√®te sans dupliquer
- Estime le temps de fa√ßon r√©aliste

R√©ponds UNIQUEMENT avec le JSON, sans texte avant ou apr√®s.`

  const response = await callLLM([{ role: 'user', content: prompt }])

  try {
    const jsonMatch = response.content.match(/\{[\s\S]*\}/)
    if (!jsonMatch) {
      throw new Error('Invalid response format')
    }
    const aiResult = JSON.parse(jsonMatch[0])

    const subtasks: GeneratedSubtask[] = (aiResult.subtasks || []).map((st: any, index: number) => ({
      title: st.title,
      estimatedMinutes: st.estimatedMinutes || 15,
      order: index,
    }))

    return {
      subtasks,
      totalEstimatedMinutes: subtasks.reduce((sum, st) => sum + st.estimatedMinutes, 0),
      tip: aiResult.tip || '',
    }
  } catch (error) {
    console.error('Error parsing subtask generation response:', error)
    throw new Error('Erreur lors de la g√©n√©ration des sous-t√¢ches')
  }
}

// ============================================
// DAILY FOCUS - Top 3 tasks for today
// ============================================

export interface FocusTask {
  taskId: string
  taskTitle: string
  workspaceName: string
  reason: string
  estimatedMinutes: number
  energyLevel: 'high' | 'medium' | 'low'
  bestTimeSlot: string
}

export interface DailyFocusResult {
  date: Date
  greeting: string
  focusTasks: FocusTask[]
  bonusTip: string
  totalEstimatedMinutes: number
}

export async function getDailyFocus(
  tasks: Task[],
  workspaces: Workspace[]
): Promise<DailyFocusResult> {
  if (!isLLMConfigured()) {
    throw new Error('IA non configur√©e. Ajoutez votre cl√© API dans les param√®tres.')
  }

  const now = new Date()
  const hour = now.getHours()
  const incompleteTasks = tasks.filter(t => !t.completed && !t.parentId)

  if (incompleteTasks.length === 0) {
    return {
      date: now,
      greeting: "Bravo ! Tu n'as aucune t√¢che en attente. Profite de ta journ√©e ! üéâ",
      focusTasks: [],
      bonusTip: "C'est le moment id√©al pour planifier tes prochains objectifs.",
      totalEstimatedMinutes: 0,
    }
  }

  const workspaceMap = new Map(workspaces.map(w => [w.id, w.name]))
  const taskContext = incompleteTasks.slice(0, 15).map((t, i) => {
    const ws = workspaceMap.get(t.workspaceId) || 'Inconnu'
    const deadline = t.deadline ? new Date(t.deadline).toLocaleDateString('fr-FR') : 'Pas de deadline'
    const stars = t.stars ? '‚≠ê'.repeat(t.stars) : ''
    const isOverdue = t.deadline && new Date(t.deadline) < now
    return `${i + 1}. [${ws}] "${t.title}" | Type: ${t.taskType} | Priorit√©: ${t.priority} ${stars} | Deadline: ${deadline}${isOverdue ? ' ‚ö†Ô∏è EN RETARD' : ''}`
  }).join('\n')

  const timeContext = hour < 12 ? 'matin' : hour < 17 ? 'apr√®s-midi' : 'soir'

  const prompt = `Tu es un coach de productivit√© expert. S√©lectionne les 3 t√¢ches les plus importantes √† accomplir aujourd'hui.

DATE/HEURE: ${now.toLocaleDateString('fr-FR')} ${now.toLocaleTimeString('fr-FR', { hour: '2-digit', minute: '2-digit' })} (${timeContext})

T√ÇCHES DISPONIBLES (${incompleteTasks.length} total, top 15 affich√©es):
${taskContext}

R√©ponds en JSON avec ce format exact:
{
  "greeting": "message d'accueil personnalis√© et motivant (1 phrase, tutoiement)",
  "focusTasks": [
    {
      "taskIndex": <num√©ro de la t√¢che>,
      "reason": "pourquoi cette t√¢che maintenant (1 phrase)",
      "estimatedMinutes": <dur√©e estim√©e en minutes>,
      "energyLevel": "high" | "medium" | "low",
      "bestTimeSlot": "cr√©neau sugg√©r√© (ex: '09:00-10:30')"
    }
  ],
  "bonusTip": "conseil bonus pour la journ√©e (1 phrase)"
}

R√àGLES:
- S√©lectionne EXACTEMENT 3 t√¢ches (ou moins si pas assez de t√¢ches)
- Priorise: t√¢ches en retard > deadline aujourd'hui > haute priorit√©/√©toiles > impact important
- energyLevel: high = concentration intense, medium = travail standard, low = t√¢ches l√©g√®res
- bestTimeSlot: adapte au moment de la journ√©e (${timeContext})
- Sois concret, motivant et bienveillant

R√©ponds UNIQUEMENT avec le JSON, sans texte avant ou apr√®s.`

  const response = await callLLM([{ role: 'user', content: prompt }])

  try {
    const jsonMatch = response.content.match(/\{[\s\S]*\}/)
    if (!jsonMatch) {
      throw new Error('Invalid response format')
    }
    const aiResult = JSON.parse(jsonMatch[0])

    const focusTasks: FocusTask[] = (aiResult.focusTasks || []).map((ft: any) => {
      const task = incompleteTasks[ft.taskIndex - 1]
      if (!task) return null
      return {
        taskId: task.id,
        taskTitle: task.title,
        workspaceName: workspaceMap.get(task.workspaceId) || 'Inconnu',
        reason: ft.reason,
        estimatedMinutes: ft.estimatedMinutes || 30,
        energyLevel: ft.energyLevel || 'medium',
        bestTimeSlot: ft.bestTimeSlot || '',
      }
    }).filter(Boolean)

    return {
      date: now,
      greeting: aiResult.greeting || "C'est parti pour une journ√©e productive !",
      focusTasks,
      bonusTip: aiResult.bonusTip || "Une t√¢che √† la fois, tu vas y arriver !",
      totalEstimatedMinutes: focusTasks.reduce((sum: number, t: FocusTask) => sum + t.estimatedMinutes, 0),
    }
  } catch (error) {
    console.error('Error parsing daily focus response:', error)
    throw new Error('Erreur lors de la g√©n√©ration du focus')
  }
}
